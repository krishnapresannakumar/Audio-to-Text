import numpy as np
import librosa
import tensorflow as tf

# Load the audio file and convert it to a spectrogram
y, sr = librosa.load('speech.wav')
spectrogram = librosa.stft(y)

# Preprocess the spectrogram
spectrogram = np.expand_dims(spectrogram, axis=-1)
spectrogram = spectrogram / np.max(np.abs(spectrogram))

# Build the CNN model
input_shape = (spectrogram.shape[0], spectrogram.shape[1], 1)
model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(32, (3,3), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))
model.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))
model.add(tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))
model.add(tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation='relu'))
model.add(tf.keras.layers.Dense(len(vocab), activation='softmax'))

# Compile and fit the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(spectrogram, labels, epochs=10, batch_size=32)

# Use the model to predict the transcript
predictions = model.predict(spectrogram)
transcript = decode_predictions(predictions, vocab)
print(transcript)
